{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from collections import deque\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in a calibration image \n",
    "image = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "plt.imshow(image)\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image)  # if you wanted to show a single color channel image called 'gray', for example, call as plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreStep1. Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in and make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Arrays to store object points and image points for all images\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "# Set chessboard size\n",
    "nx = 9  # the number of inside corners in x\n",
    "ny = 6  # the number of inside corners in y\n",
    "\n",
    "# Prepare object points, like(0,0,0), (1,0,0), ...,(8,5,0)\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2) # x, y cordinates\n",
    "\n",
    "# Plot the original images and images with found corners\n",
    "f,ax = plt.subplots(17,3,figsize=(15,60))\n",
    "f.tight_layout()\n",
    "ind = 0    \n",
    "for fname in images:\n",
    "    # Read in each image\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    # Covert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        print(fname)\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        # Draw and display the corners\n",
    "        img_corner = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        ax[ind,0].imshow(img)\n",
    "        ax[ind,1].imshow(gray)    \n",
    "        ax[ind,2].imshow(img_corner)\n",
    "        ax[ind,0].set_xticks([])\n",
    "        ax[ind,0].set_yticks([])\n",
    "        ax[ind,0].set_title('Original Chessboard Image #' + str(ind))\n",
    "\n",
    "        ax[ind,1].set_xticks([])\n",
    "        ax[ind,1].set_yticks([])\n",
    "        ax[ind,1].set_title('Grayscale Chessboard Image #' + str(ind))\n",
    "\n",
    "        ax[ind,2].set_xticks([])\n",
    "        ax[ind,2].set_yticks([])\n",
    "        ax[ind,2].set_title('Chessboard Image with corners #' + str(ind))           \n",
    "        ind = ind + 1\n",
    "        \n",
    "    \n",
    "# Use the object and image points to calibrate the camera and compute the camera matrix and distortion coefficients\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreStep2.  Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create Function to Undistort and Calibrate Image \n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    ret, mtx, dist, rvecs, trecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "# Plot the original images and undistort images\n",
    "f,ax = plt.subplots(20,2,figsize=(15,60))\n",
    "f.tight_layout()\n",
    "ind = 0  \n",
    "for fname in images:\n",
    "    # Read in each image\n",
    "    img = cv2.imread(fname)\n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "    plt.imsave('output_images/' + 'undistort#' + str(ind) + '.jpg', undistorted)\n",
    "    \n",
    "    # Draw and display the corners\n",
    "    ax[ind,0].imshow(img)\n",
    "    ax[ind,1].imshow(undistorted)    \n",
    "    ax[ind,0].set_xticks([])\n",
    "    ax[ind,0].set_yticks([])\n",
    "    ax[ind,0].set_title('Original Chessboard Image #' + str(ind))\n",
    "\n",
    "    ax[ind,1].set_xticks([])\n",
    "    ax[ind,1].set_yticks([])\n",
    "    ax[ind,1].set_title('Undistort Chessboard Image #' + str(ind))       \n",
    "    ind = ind + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreStep3.  Perspective Transform on Chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corners_unwarp(img, nx, ny, mtx, dist):\n",
    "    # 1) Undistort using mtx and dist\n",
    "    undist = cal_undistort(img, objpoints, imgpoints)\n",
    "    # 2) Convert to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY )\n",
    "    # 3) Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # 4) If corners found: \n",
    "    if ret == True:\n",
    "            # a) draw corners\n",
    "            cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "            # b) define 4 source points src = np.float32([[,],[,],[,],[,]])\n",
    "            src = np.float32([corners[0], corners[nx - 1], corners[-1], corners[-nx]]);\n",
    "            # c) define 4 destination points dst = np.float32([[,],[,],[,],[,]])\n",
    "            img_size = (img.shape[1], img.shape[0])\n",
    "            offset = 100 # offset for dst points\n",
    "            dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "            # d) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "            M = cv2.getPerspectiveTransform(src, dst)\n",
    "            # e) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "            warped = cv2.warpPerspective(undist, M, img_size)\n",
    "\n",
    "    return warped, M\n",
    "\n",
    "# Create Function to Undistort and Calibrate Image \n",
    "img = mpimg.imread('camera_cal/calibration3.jpg')\n",
    "\n",
    "top_down, perspective_M = corners_unwarp(img, nx, ny, mtx, dist)\n",
    "# Plot the original and undistorted images\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Load in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'test_images/'\n",
    "                \n",
    "lanes = []\n",
    "\n",
    "images = os.listdir(img_dir)\n",
    "for image in images:\n",
    "    if image.endswith('.png') or image.endswith('.jpg'):\n",
    "        img = mpimg.imread(os.path.join(img_dir,image))\n",
    "        lanes.append(img)\n",
    "\n",
    "f,ax = plt.subplots(len(lanes),1,figsize=(20,30))\n",
    "for i in range(len(lanes)):\n",
    "    ax[i].imshow(lanes[i])   \n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    ax[i].set_title('Test Lane Image #' + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Color/Gradient threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1). Applying sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0,255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply Sobel and take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobelx = np.absolute(abs_sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # Return mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "# Read in an image\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "# Apply function\n",
    "sobelx = abs_sobel_thresh(img, orient='x',sobel_kernel=3, thresh=(25, 170))\n",
    "sobely = abs_sobel_thresh(img, orient='y',sobel_kernel=3, thresh=(20, 255))\n",
    "\n",
    "# Plot the original and undistorted images\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 15))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(sobelx, cmap='gray')\n",
    "ax2.set_title('Thresholded x-derivated', fontsize=30)\n",
    "ax3.imshow(sobely, cmap='gray')\n",
    "ax3.set_title('Thresholded y-derivated', fontsize=30)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2). Magnitude of the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Read in an image\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "# Run the function\n",
    "magnitude = mag_thresh(img, sobel_kernel=3, mag_thresh=(10,100))\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(magnitude, cmap='gray')\n",
    "ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3). Direction of the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Read in an image\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "# Run the function\n",
    "direction = dir_threshold(img, sobel_kernel=3, thresh=(0.1, 1.2))\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(direction, cmap='gray')\n",
    "ax2.set_title('Thresholded Grad. Dir.', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4). HLS and Combined Color Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function that thresholds the combination of the S-channel and L-channel in HLS\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    s_channel = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)[:,:,2]\n",
    "    \n",
    "    l_channel = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)[:,:,0]\n",
    "\n",
    "\n",
    "    # Threshold color channel\n",
    "    s_thresh_min = 65\n",
    "    s_thresh_max = 255\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "    \n",
    "    \n",
    "    l_thresh_min = 185\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "    # Stack each channel to view their individual contributions in green and blue respectively\n",
    "    # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "    color_binary = np.dstack(( np.zeros_like(s_binary), s_binary, l_binary)) * 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(s_binary)\n",
    "    combined_binary[(l_binary == 1) | (s_binary == 1)] = 1\n",
    "    return combined_binary, color_binary\n",
    "\n",
    "# Read in an image\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "# Run the function\n",
    "hls_binary, color_binary = hls_select(img)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(30, 15))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(color_binary)\n",
    "ax2.set_title('Stacked thresholds', fontsize=30)\n",
    "ax3.imshow(hls_binary, cmap='gray')\n",
    "ax3.set_title('Combined S channel and L channel thresholds', fontsize=30)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Perspective Transform on testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_bottom_left = [500,525] \n",
    "src_bottom_right = [800, 550]\n",
    "src_top_left = [600, 450]\n",
    "src_top_right = [675, 450]\n",
    "\n",
    "src = np.float32([src_bottom_left,src_bottom_right,src_top_right,src_top_left])\n",
    "\n",
    "dst_bottom_left = [320,720] \n",
    "dst_bottom_right = [920, 720]\n",
    "dst_top_left = [320, 1]\n",
    "dst_top_right = [920, 1]\n",
    "\n",
    "dst = np.float32([dst_bottom_left,dst_bottom_right,dst_top_right,dst_top_left])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "def perspective_transform(img, M):\n",
    "    warped = cv2.warpPerspective(img, M, dsize = (img.shape[1],img.shape[0]), flags = cv2.INTER_LINEAR)\n",
    "    return warped\n",
    "\n",
    "# Read in an image\n",
    "img = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "\n",
    "# Run the function\n",
    "warped = perspective_transform(img, M)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(warped, cmap='gray')\n",
    "ax2.set_title('Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.  Define pipeline for image preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(img):\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    warped = perspective_transform(img, M)\n",
    "    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    gradx = abs_sobel_thresh(warped, orient='x', sobel_kernel=3, thresh=(10, 230))\n",
    "    grady = abs_sobel_thresh(warped, orient='y', sobel_kernel=3, thresh=(10, 230))\n",
    "    mag_binary = mag_thresh(warped, sobel_kernel=3, mag_thresh=(30, 150))\n",
    "    dir_binary = dir_threshold(warped, sobel_kernel=3, thresh=(0.7, 1.3))\n",
    "    hls_binary, color_binary = hls_select(warped)\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (hls_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a list of example images\n",
    "images = glob.glob('./test_images/*.jpg')\n",
    "                                          \n",
    "# Set up plot\n",
    "fig, axs = plt.subplots(len(images), 2, figsize=(15, 40))\n",
    "f.tight_layout()\n",
    "ind = 0    \n",
    "                  \n",
    "# Apply pipeline to all test images and plot the images\n",
    "i = 0\n",
    "for image in images:\n",
    "    img = mpimg.imread(image)\n",
    "    binary_warped = preprocess_pipeline(img)\n",
    "    axs[i, 0].imshow(img)\n",
    "    axs[i, 1].imshow(binary_warped, cmap='gray')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.  Sliding Windows search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a thresholded image\n",
    "warped = binary_warped\n",
    "# window settings\n",
    "window_width = 50 \n",
    "window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "margin = 100 # How much to slide left and right for searching\n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(image, window_width, window_height, margin):\n",
    "    \n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "\n",
    "    return window_centroids\n",
    "\n",
    "window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "\n",
    "# If we found any window centers\n",
    "if len(window_centroids) > 0:\n",
    "\n",
    "    # Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "\n",
    "    # Go through each level and draw the windows \t\n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    " \n",
    " # If no window centers found, just display orginal road image\n",
    "else:\n",
    "    output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "\n",
    "# Display the final results\n",
    "plt.imshow(output)\n",
    "plt.title('window fitting results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Locate the Lane Lines and Fit a Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = binary_warped\n",
    "\n",
    "def histogram_pixel_peaks(combined):\n",
    "    # Assuming you have created a warped binary image called \"combined\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(combined[combined.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((combined, combined, combined))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(combined.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = combined.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 80\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = combined.shape[0] - np.int((window+1)*window_height)\n",
    "        win_y_high = combined.shape[0] - np.int(window*window_height)\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "leftx, lefty, rightx, righty, out_img = histogram_pixel_peaks(combined)\n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[lefty, leftx] = [255, 0, 0]\n",
    "out_img[righty, rightx] = [0, 0, 255]\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_3p_circle_radius(x1,y1,x2,y2,x3,y3):\n",
    "    \n",
    "    # source : http://www.intmath.com/applications-differentiation/8-radius-curvature.php\n",
    "    m1 = (y2-y1)/(x2-x1)\n",
    "    m2 = (y3-y2)/(x3-x2)\n",
    "    \n",
    "    xc = (m1*m2*(y1-y3)+m2*(x1+x2)-m1*(x2+x3))/(2*(m2-m1))\n",
    "    yc = -(xc-(x1+x2)/2)/m1+(y1+y2)/2\n",
    "    \n",
    "    Radius = np.sqrt((x2-xc)*(x2-xc)+(y2-yc)*(y2-yc))\n",
    "    \n",
    "    return m1, m2, xc, yc, Radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some fake data to represent lane-line pixels\n",
    "ploty = np.linspace(0, 719, num=720)# to cover same y-range as image\n",
    "quadratic_coeff = 3e-4 # arbitrary quadratic coefficient\n",
    "# For each y position generate random x position within +/-50 pix\n",
    "# of the line base position in each case (x=200 for left, and x=900 for right)\n",
    "leftx = np.array([200 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                              for y in ploty])\n",
    "rightx = np.array([900 + (y**2)*quadratic_coeff + np.random.randint(-50, high=51) \n",
    "                                for y in ploty])\n",
    "\n",
    "leftx = leftx[::-1]  # Reverse to match top-to-bottom in y\n",
    "rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "\n",
    "\n",
    "# Fit a second order polynomial to pixel positions in each fake lane line\n",
    "left_fit = np.polyfit(ploty, leftx, 2)\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fit = np.polyfit(ploty, rightx, 2)\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "# Plot up the fake data\n",
    "mark_size = 3\n",
    "plt.plot(leftx, ploty, 'o', color='red', markersize=mark_size)\n",
    "plt.plot(rightx, ploty, 'o', color='blue', markersize=mark_size)\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(0, 720)\n",
    "plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "plt.gca().invert_yaxis() # to visualize as we do the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Implement pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    ksize = 3\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    img = cv2.resize(img, (720, 405))\n",
    "    warped = perspective_transform(img, M)\n",
    "    gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    gradx = abs_sobel_thresh(warped, orient='x', sobel_kernel=3, thresh=(10, 255))\n",
    "    grady = abs_sobel_thresh(warped, orient='y', sobel_kernel=3, thresh=(1, 255))\n",
    "    mag_binary = mag_thresh(warped, sobel_kernel=ksize, mag_thresh=(30, 255))\n",
    "    dir_binary = dir_threshold(warped, sobel_kernel=ksize, thresh=(0, 1.7))\n",
    "    hls_binary, color_binary = hls_select(warped)\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((grady == 1) & (hls_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1 \n",
    "          \n",
    "    leftx, lefty, rightx, righty, out_img = histogram_pixel_peaks(combined)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    yvals = np.linspace(0, combined.shape[0], num=combined.shape[0])\n",
    "\n",
    "    # Fit a second order polynomial to each lane line\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals**2 + left_fit[1]*yvals + left_fit[2]\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals**2 + right_fit[1]*yvals + right_fit[2]\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 25/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/675 # meteres per pixel in x dimension\n",
    "    # Define y-value where we want radius of curvature\n",
    "    # I'll choose 3 y-values(max, mean and min):\n",
    "    y_eval = np.max(yvals)\n",
    "    \n",
    "    y_eval1 = np.max(yvals)\n",
    "    y_eval2 = np.mean(yvals)\n",
    "    y_eval3 = np.min(yvals)\n",
    "    left_fitx_1 = left_fit[0]*y_eval1**2 + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx_2 = left_fit[0]*y_eval2**2 + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx_3 = left_fit[0]*y_eval3**2 + left_fit[1]*yvals + left_fit[2]\n",
    "    right_fitx_1 = right_fit[0]*y_eval1**2 + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx_2 = right_fit[0]*y_eval2**2 + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx_3 = right_fit[0]*y_eval3**2 + right_fit[1]*yvals + right_fit[2]\n",
    "    \n",
    "    \n",
    "    # Calculated the turning center point xc, yc and radius: \n",
    "            \n",
    "    lm1, lm2, lxc, lyc, lradius = find_3p_circle_radius(left_fitx_1,y_eval1,left_fitx_2,y_eval2,left_fitx_3,y_eval3,)\n",
    "    l_steering_angle = 5*360/lxc # assume xc <> 0, xc and radius value is very close, xc will show the direction as well\n",
    "    \n",
    "    \n",
    "    rm1, rm2, rxc, ryc, rradius = find_3p_circle_radius(right_fitx_1,y_eval1,right_fitx_2,y_eval2,right_fitx_3,y_eval3,)\n",
    "     \n",
    "    r_steering_angle = 5*360/rxc # assume xc <> 0, xc and radius value is very close, xc will show the direction as well\n",
    "    steering_angle = l_steering_angle + r_steering_angle\n",
    "    turning_radius = (lradius+rradius)/2 # smooth out the radius\n",
    "    \n",
    "    # Find camera position\n",
    "    #left_mean = np.mean(leftx)\n",
    "    #right_mean = np.mean(rightx)\n",
    "    #camera_pos = (combined.shape[1]/2)-np.mean([left_mean, right_mean])\n",
    "    leftx_int = left_fit[0]*720**2 + left_fit[1]*720 + left_fit[2]\n",
    "    rightx_int = right_fit[0]*720**2 + right_fit[1]*720 + right_fit[2]\n",
    "    camera_pos = abs(640 - ((rightx_int+leftx_int)/2))\n",
    "\n",
    "    left_fit_cr = np.polyfit(np.array(lefty,dtype=np.float32)*ym_per_pix, \\\n",
    "                         np.array(leftx,dtype=np.float32)*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(np.array(righty,dtype=np.float32)*ym_per_pix, \\\n",
    "                          np.array(rightx,dtype=np.float32)*xm_per_pix, 2)\n",
    "    \n",
    "    # Return radius of curvature is in meters\n",
    "    \n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    turning_radius = (left_curverad+right_curverad)/2 \n",
    "    \n",
    "    # Link all points for cv2.fillPoly() in pix space\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    #color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    cv2.fillPoly(warp_zero, np.int_([pts]), (0,255, 0))\n",
    "    cv2.polylines(warp_zero, np.array([pts_left], dtype=np.int32), False,(255,0,0),thickness = 15)\n",
    "    cv2.polylines(warp_zero, np.array([pts_right], dtype=np.int32), False,(0,0,255),thickness = 15)\n",
    "    #font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #cv2.putText(img,'Left curve' + ' ' + str(left_curverad)[:6] + 'm',(10,60), font, 1,(255,255,255),1)\n",
    "    cv2.putText(img,'Camera Position' + ' [' + str(camera_pos*xm_per_pix)[:6] + '] m',(10,30), font, 1,(255,255,255),2)\n",
    "    cv2.putText(img,'Curvature Radius '+ '[' +str(turning_radius)[:6] + '] m' ,(10,60), font, 1,(255,255,255),2)\n",
    "    #cv2.putText(img, 'Turning Radius = %.2f m' % np.array(turning_radius), (10, 40), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img,'Steering Angle '+'{:.6}'.format(str(steering_angle)) + '] deg',(10,90), font, 1,(255,255,255),2)\n",
    "    \n",
    "    # Warp back to original view\n",
    "    unwarp = perspective_transform(warp_zero, Mi)\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(img, 1, unwarp, 0.3, 0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for img in glob.glob('test_images/*.jpg'):\n",
    "    image = mpimg.imread(img)\n",
    "\n",
    "    apex, apey = 360, 258\n",
    "    offset_far = 48\n",
    "    offset_near = 2\n",
    "    src = np.float32([[int(apex-offset_far),apey],\n",
    "                      [int(apex+offset_far),apey],\n",
    "                      [int(0+offset_near),390],\n",
    "                      [int(720-offset_near),390]])\n",
    "    dst = np.float32([[0,0],[720,0],[0,405],[720,405]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Mi = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    result = pipeline(image)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(result,cmap='gray' )\n",
    "    ax2.set_title('Undistorted Image', fontsize=20)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line:\n",
    "    def __init__(self):\n",
    "        # Was the line found in the previous frame?\n",
    "        self.found = False\n",
    "        \n",
    "        # Remember x and y values of lanes in previous frame\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        \n",
    "        # Store recent x intercepts for averaging across frames\n",
    "        self.x_int = deque(maxlen=10)\n",
    "        self.top = deque(maxlen=10)\n",
    "        \n",
    "        # Remember previous x intercept to compare against current one\n",
    "        self.lastx_int = None\n",
    "        self.last_top = None\n",
    "        \n",
    "        # Remember radius of curvature\n",
    "        self.radius = None\n",
    "        \n",
    "        # Store recent polynomial coefficients for averaging across frames\n",
    "        self.fit0 = deque(maxlen=10)\n",
    "        self.fit1 = deque(maxlen=10)\n",
    "        self.fit2 = deque(maxlen=10)\n",
    "        self.fitx = None\n",
    "        self.pts = []\n",
    "        \n",
    "        # Count the number of frames\n",
    "        self.count = 0\n",
    "        \n",
    "    def found_search(self, x, y):\n",
    "        '''\n",
    "        This function is applied when the lane lines have been detected in the previous frame.\n",
    "        It uses a sliding window to search for lane pixels in close proximity (+/- 25 pixels in the x direction)\n",
    "        around the previous detected polynomial. \n",
    "        '''\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == True: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                yval = np.mean([i,j])\n",
    "                xval = (np.mean(self.fit0))*yval**2 + (np.mean(self.fit1))*yval + (np.mean(self.fit2))\n",
    "                x_idx = np.where((((xval - 25) < x)&(x < (xval + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    np.append(xvals, x_window)\n",
    "                    np.append(yvals, y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) == 0: \n",
    "            self.found = False # If no lane pixels were detected then perform blind search\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    def blind_search(self, x, y, image):\n",
    "        '''\n",
    "        This function is applied in the first few frames and/or if the lane was not successfully detected\n",
    "        in the previous frame. It uses a slinding window approach to detect peaks in a histogram of the\n",
    "        binary thresholded image. Pixels in close proimity to the detected peaks are considered to belong\n",
    "        to the lane lines.\n",
    "        '''\n",
    "        xvals = []\n",
    "        yvals = []\n",
    "        if self.found == False: \n",
    "            i = 720\n",
    "            j = 630\n",
    "            while j >= 0:\n",
    "                histogram = np.sum(image[j:i,:], axis=0)\n",
    "                if self == Right:\n",
    "                    peak = np.argmax(histogram[640:]) + 640\n",
    "                else:\n",
    "                    peak = np.argmax(histogram[:640])\n",
    "                x_idx = np.where((((peak - 25) < x)&(x < (peak + 25))&((y > j) & (y < i))))\n",
    "                x_window, y_window = x[x_idx], y[x_idx]\n",
    "                if np.sum(x_window) != 0:\n",
    "                    xvals.extend(x_window)\n",
    "                    yvals.extend(y_window)\n",
    "                i -= 90\n",
    "                j -= 90\n",
    "        if np.sum(xvals) > 0:\n",
    "            self.found = True\n",
    "        else:\n",
    "            yvals = self.Y\n",
    "            xvals = self.X\n",
    "        return xvals, yvals, self.found\n",
    "    \n",
    "    def radius_of_curvature(self, xvals, yvals):\n",
    "        ym_per_pix = 25./720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/675 # meteres per pixel in x dimension\n",
    "        fit_cr = np.polyfit(yvals*ym_per_pix, xvals*xm_per_pix, 2)\n",
    "        curverad = ((1 + (2*fit_cr[0]*np.max(yvals)*ym_per_pix + fit_cr[1])**2)**1.5)/np.absolute(2*fit_cr[0])\n",
    "        return curverad\n",
    "    \n",
    "    def sort_vals(self, xvals, yvals):\n",
    "        sorted_index = np.argsort(yvals)\n",
    "        sorted_yvals = yvals[sorted_index]\n",
    "        sorted_xvals = xvals[sorted_index]\n",
    "        return sorted_xvals, sorted_yvals\n",
    "    \n",
    "    def get_intercepts(self, polynomial):\n",
    "        bottom = polynomial[0]*720**2 + polynomial[1]*720 + polynomial[2]\n",
    "        top = polynomial[0]*0**2 + polynomial[1]*0 + polynomial[2]\n",
    "        return bottom, top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video Processing Pipeline\n",
    "def process_vid(image):\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    \n",
    "    # Calibrate camera and undistort image\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Perform perspective transform\n",
    "    offset = 0\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                      [1250, 720],[0, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    warped = cv2.warpPerspective(undist, M, img_size)\n",
    "    \n",
    "    # Generate binary thresholded images\n",
    "    r_channel = warped[:,:,2]\n",
    "    b_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2Lab)[:,:,2]\n",
    "    l_channel = cv2.cvtColor(warped, cv2.COLOR_RGB2LUV)[:,:,0]  \n",
    "    \n",
    "    # Set the upper and lower thresholds for the r channel\n",
    "    r_thresh_min = 225\n",
    "    r_thresh_max = 255\n",
    "    r_binary = np.zeros_like(r_channel)\n",
    "    r_binary[(r_channel >= r_thresh_min) & (r_channel <= r_thresh_max)] = 1\n",
    "    \n",
    "    # Set the upper and lower thresholds for the b channel\n",
    "    b_thresh_min = 145\n",
    "    b_thresh_max = 200\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "    \n",
    "    # Set the upper and lower thresholds for the l channel\n",
    "    l_thresh_min = 215\n",
    "    l_thresh_max = 255\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh_min) & (l_channel <= l_thresh_max)] = 1\n",
    "\n",
    "    combined_binary = np.zeros_like(b_binary)\n",
    "    combined_binary[(r_binary == 1) |(l_binary == 1) | (b_binary == 1)] = 1\n",
    "    \n",
    "    # Identify all non zero pixels in the image\n",
    "    x, y = np.nonzero(np.transpose(combined_binary)) \n",
    "\n",
    "    if Left.found == True: # Search for left lane pixels around previous polynomial\n",
    "        leftx, lefty, Left.found = Left.found_search(x, y)\n",
    "        \n",
    "    if Right.found == True: # Search for right lane pixels around previous polynomial\n",
    "        rightx, righty, Right.found = Right.found_search(x, y)\n",
    "\n",
    "            \n",
    "    if Right.found == False: # Perform blind search for right lane lines\n",
    "        rightx, righty, Right.found = Right.blind_search(x, y, combined_binary)\n",
    "            \n",
    "    if Left.found == False:# Perform blind search for left lane lines\n",
    "        leftx, lefty, Left.found = Left.blind_search(x, y, combined_binary)\n",
    "\n",
    "    lefty = np.array(lefty).astype(np.float32)\n",
    "    leftx = np.array(leftx).astype(np.float32)\n",
    "    righty = np.array(righty).astype(np.float32)\n",
    "    rightx = np.array(rightx).astype(np.float32)\n",
    "            \n",
    "    # Calculate left polynomial fit based on detected pixels\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    \n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    leftx_int, left_top = Left.get_intercepts(left_fit)\n",
    "    \n",
    "    # Average intercepts across n frames\n",
    "    Left.x_int.append(leftx_int)\n",
    "    Left.top.append(left_top)\n",
    "    leftx_int = np.mean(Left.x_int)\n",
    "    left_top = np.mean(Left.top)\n",
    "    Left.lastx_int = leftx_int\n",
    "    Left.last_top = left_top\n",
    "    \n",
    "    # Add averaged intercepts to current x and y vals\n",
    "    leftx = np.append(leftx, leftx_int)\n",
    "    lefty = np.append(lefty, 720)\n",
    "    leftx = np.append(leftx, left_top)\n",
    "    lefty = np.append(lefty, 0)\n",
    "    \n",
    "    # Sort detected pixels based on the yvals\n",
    "    leftx, lefty = Left.sort_vals(leftx, lefty)\n",
    "    \n",
    "    Left.X = leftx\n",
    "    Left.Y = lefty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    Left.fit0.append(left_fit[0])\n",
    "    Left.fit1.append(left_fit[1])\n",
    "    Left.fit2.append(left_fit[2])\n",
    "    left_fit = [np.mean(Left.fit0), \n",
    "                np.mean(Left.fit1), \n",
    "                np.mean(Left.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    left_fitx = left_fit[0]*lefty**2 + left_fit[1]*lefty + left_fit[2]\n",
    "    Left.fitx = left_fitx\n",
    "    \n",
    "    # Calculate right polynomial fit based on detected pixels\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Calculate intercepts to extend the polynomial to the top and bottom of warped image\n",
    "    rightx_int, right_top = Right.get_intercepts(right_fit)\n",
    "    \n",
    "    # Average intercepts across 5 frames\n",
    "    Right.x_int.append(rightx_int)\n",
    "    rightx_int = np.mean(Right.x_int)\n",
    "    Right.top.append(right_top)\n",
    "    right_top = np.mean(Right.top)\n",
    "    Right.lastx_int = rightx_int\n",
    "    Right.last_top = right_top\n",
    "    rightx = np.append(rightx, rightx_int)\n",
    "    righty = np.append(righty, 720)\n",
    "    rightx = np.append(rightx, right_top)\n",
    "    righty = np.append(righty, 0)\n",
    "    \n",
    "    # Sort right lane pixels\n",
    "    rightx, righty = Right.sort_vals(rightx, righty)\n",
    "    Right.X = rightx\n",
    "    Right.Y = righty\n",
    "    \n",
    "    # Recalculate polynomial with intercepts and average across n frames\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    Right.fit0.append(right_fit[0])\n",
    "    Right.fit1.append(right_fit[1])\n",
    "    Right.fit2.append(right_fit[2])\n",
    "    right_fit = [np.mean(Right.fit0), np.mean(Right.fit1), np.mean(Right.fit2)]\n",
    "    \n",
    "    # Fit polynomial to detected pixels\n",
    "    right_fitx = right_fit[0]*righty**2 + right_fit[1]*righty + right_fit[2]\n",
    "    Right.fitx = right_fitx\n",
    "        \n",
    "    # Compute radius of curvature for each lane in meters\n",
    "    left_curverad = Left.radius_of_curvature(leftx, lefty)\n",
    "    right_curverad = Right.radius_of_curvature(rightx, righty)\n",
    "        \n",
    "    # Only print the radius of curvature every 3 frames for improved readability\n",
    "    if Left.count % 3 == 0:\n",
    "        Left.radius = left_curverad\n",
    "        Right.radius = right_curverad\n",
    "        \n",
    "    # Calculate the vehicle position relative to the center of the lane\n",
    "    position = (rightx_int+leftx_int)/2\n",
    "    distance_from_center = abs((640 - position)*3.7/900) \n",
    "                \n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    \n",
    "    warp_zero = np.zeros_like(combined_binary).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    pts_left = np.array([np.flipud(np.transpose(np.vstack([Left.fitx, Left.Y])))])\n",
    "    pts_right = np.array([np.transpose(np.vstack([right_fitx, Right.Y]))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.polylines(color_warp, np.int_([pts]), isClosed=False, color=(0,0,255), thickness = 40)\n",
    "    cv2.fillPoly(color_warp, np.int_(pts), (34,255,34))\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0]))\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.5, 0)\n",
    "        \n",
    "    # Print distance from center on video\n",
    "    if position > 640:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m left of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    else:\n",
    "        cv2.putText(result, 'Vehicle is {:.2f}m right of center'.format(distance_from_center), (100,80),\n",
    "                 fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    # Print radius of curvature on video\n",
    "    cv2.putText(result, 'Radius of Curvature {}(m)'.format(int((Left.radius+Right.radius)/2)), (120,140),\n",
    "             fontFace = 16, fontScale = 2, color=(255,255,255), thickness = 2)\n",
    "    Left.count += 1\n",
    "    \n",
    "    # Multiview video output for diagnostic purpose\n",
    "    diagnostic_output = True\n",
    "    if diagnostic_output:\n",
    "        diag_img = np.zeros((720,1280,3), dtype=np.uint8)\n",
    "        # original output (top left)\n",
    "        diag_img[0:360,0:640,:] = cv2.resize(result,(640,360))\n",
    "        \n",
    "        # binary overhead view (top right)\n",
    "        combined_binary = np.dstack((combined_binary*255, combined_binary*255, combined_binary*255))\n",
    "        resized_combined_binary = cv2.resize(combined_binary,(640,360))\n",
    "        diag_img[0:360,640:1280, :] = resized_combined_binary\n",
    "        \n",
    "        # overhead with all fits added (bottom right)\n",
    "        combined_binary_fit = combined_binary.copy()\n",
    "        #cv2.line(combined_binary_fit,righty,Right.fitx,color=(0,255,255),thickness = 4)\n",
    "        #cv2.line(combined_binary_fit,lefty,Left.fitx,color=(0,255,255),thickness = 4)\n",
    "        combined_binary_fit = plot_fit_onto_img(combined_binary_fit, right_fit, (255,255,0))\n",
    "        combined_binary_fit = plot_fit_onto_img(combined_binary_fit, left_fit, (255,255,0))\n",
    "        diag_img[360:720,640:1280,:] = cv2.resize(combined_binary_fit,(640,360))\n",
    "        result = diag_img\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fit_onto_img(img, fit, plot_color):\n",
    "    if fit is None:\n",
    "        return img\n",
    "    new_img = np.copy(img)\n",
    "    h = new_img.shape[0]\n",
    "    ploty = np.linspace(0, h-1, h)\n",
    "    plotx = fit[0]*ploty**2 + fit[1]*ploty + fit[2]\n",
    "    pts = np.array([np.transpose(np.vstack([plotx, ploty]))])\n",
    "    cv2.polylines(new_img, np.int32([pts]), isClosed=False, color=plot_color, thickness=8)\n",
    "    return new_img\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(0,50)\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'challenge_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,16)\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Left = Line()\n",
    "Right = Line()\n",
    "video_output = 'harder_challenge_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"harder_challenge_video.mp4\").subclip(0,10)\n",
    "white_clip = clip1.fl_image(process_vid) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video_output.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('challenge_video_output.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('harder_challenge_video_output.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
